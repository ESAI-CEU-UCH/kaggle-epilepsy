\documentclass[a4paper,english,twoside]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{babel}
\usepackage{xspace}
\usepackage{amsmath}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{calc}
\usepackage{anysize}
\usepackage{url}
\marginsize{3.5cm}{3cm}{3.5cm}{3.5cm}

%% %% Cabecera - Start %%
\fancyhf{}
\fancyhead[LO,RE]{\small \emph{Seizure prediction system of ESAI-CEU-UCH team}}
\fancyhead[RO,LE]{}
\fancyfoot[C]{\bfseries \thepage}
\renewcommand{\headrulewidth}{0.5pt}  % headrule
\pagestyle{fancy}
%% %% Cabecera - End %%

\newcommand{\etc}{etc.\@\xspace}
% \setlength{\extrarowheight}{-5em}

\newcommand{\argmax}{\mathop{\mbox{argmax}}}

% \name{}
\author{Francisco Zamora Mart√≠nez, Francisco J. Mu\~noz--Almaraz,\\
  Paloma Botella--Rocamora, Juan Pardo}
\date{November 2014}
% \address{}
\title{Seizure prediction using FFT, eigen values of correlation matrix,
  artificial neural networks, k-nearest-neighbors and Bayesian model combination}

\begin{document}
\maketitle

\begin{itemize}
\item[Location:] Universidad CEU Cardenal Herrera, Alfara del Patriarca,
  Valencia, Spain. Embedded Systems and Artificial Intelligence (ESAI) research
  group.
\item[Email:] \{francisco.zamora, malmaraz, pbotella, juaparal\}@uch.ceu.es
\item[Competition:] American Epilepsy Society Seizure Prediction Challenge.
\end{itemize}

\section{Summary}\label{summary}

This work presents the system proposed by Universidad CEU Cardenal
Herrera (ESAI-CEU-UCH) at Kaggle American Epilepsy Society Seizure
Prediction Challenge. The proposed system was positioned as \textbf{4th}
at Kaggle American Epilepsy Society Seizure Prediction Challenge~\cite{kaggle}.

Different kind of input features (different preprocessing pipelines) and
different statistical models are being proposed. This diversity was motivated to
improve model combination result.

It is important to note that none of the proposed systems use test set
for any calibration or related purpose. The competition rules allow to do this
model calibration using test set, but doing it will reduce the
reproducibility of the results in a real world implementation.

\section{Feature selection and
  extraction}\label{feature-selection-and-extraction}

Several preprocessing pipelines have been performed. The most relevant
preprocessing technique according to final performance is FFT plus PCA
procedure. This pipeline combines methods implemented in R~\cite{Rproject} and
others in APRIL-ANN toolkit~\cite{aprilann}.

\subsection{FFT features plus PCA/ICA}\label{fft-features-plus-pcaica}

This is the most important kind of proposed features, obtaining the best
standalone result. This process follows the following steps for each input
file~\cite{2014:howbert:plosone}:

\begin{enumerate}
\item
  Extract windows of 60 seconds size with 50\% overlapping for every
  channel in the data, increasing the number of samples in the data set.
  We obtained 19 windows for every input file. Every sample is filtered
  by using Hamming windows.
\item
  For every window, real FFT is computed using an algorithm which needs
  power of two window sizes, so, 60s input windows are of 24\,000 for Dogs
  and 300\,000 for Patients, leading into 16384 FFT bins for Dogs and
  262144 FFT for Patients.
\item A filter bank is computed for bands: delta (0.1Hz --- 4Hz), theta (4Hz ---
  8Hz), alpha (8Hz --- 12Hz), beta (12Hz --- 30Hz), low-gamma (30Hz --- 70Hz),
  high-gamma (70Hz --- 180Hz). The mean in the corresponding frequency bands has
  been computed.
\item
  The output of the filter bank is compressed by computing the logarithm
  of the values.
\end{enumerate}

For every file, it is computed a matrix with 19 rows (windows of 60s with 50\%
overlapping) and $6C$ columns being $C$ the number of channels. This FFT
transformation has been applied for all the available data, training and test.

A PCA transformation has been computed over the concatenation by rows of all
training data matrices, leaving test data hidden for this step. Data have been
centered and scaled before PCA. After computing centers, scales and PCA matrix
transformation, it has been applied to all the available data, training and
test. In a similar fashion to PCA, Independent Component Analysis (ICA) has
been performed. The advantage of PCA/ICA transformation is their ability to
remove linear correlations between features.

\subsection{Eigen values of pairwise channels correlation
  matrix}\label{eigen-values-of-pairwise-channels-correlation-matrix}

This preprocessing was based in previous competition system of Michael
Hills~\cite{michaelhills}.

\subsubsection{Windowed correlation
  matrix}\label{windowed-correlation-matrix}

Correlations between the channels with windows covering 60\,s are calculated and
the eigenvalues of the correlation matrix are taken as  features for
training with KNN and ANN models (see
section~\ref{k-nearest-neighbors} and
\ref{artificial-neural-networks}). 
Every 10 minutes segment provided in the competition data set generates 19 signal subintervals whose lapse is  60\,s
overlapping 30\,s with the previous and the posterior subintervals.
Each subinterval corresponds to a data set that consists in  a matrix whose size is the number
of channels times the product of the sampling frequency and 60.
For every subinterval (window covering 60\,s) the eigenvalues of its correlation
matrix are calculated and  stored in a new file in the
folder \verb@$WINDOWED_COR_PATH@. %$
With the former procedure, the number of covariables got is 19 times the number
of channel in the individual.  Therefore, the number of features is
different 
depending on the individual.

Correlations were also calculated with the FFT transformation of every
sequence described in section~\ref{fft-features-plus-pcaica},
but the results were not stable enough.

\subsubsection{Global correlation
  matrix}\label{global-correlation-matrix}

The whole segment in a segment provided in the competition is analysed to find
correlations between channels.  The set of features  got with with
analysis was used with KNN models for training.
 Not only is considered the original signal in the
sequence, but also a differentiated  signal consisting in the difference of two consecutive
values of the original signal. The original signal is a matrix whose size is the number of
channels times the product of the frequency sampling and 600. The functions \verb@eigen@
and \verb@cor@ in R are applied to this matrix and the output are the eigenvalues of
the correlation matrix. The number of eigenvalues is equal to the number of channels for
each individuals.

For each channel signal, a transformed signal is got with the difference between
two consecutive values of the signal.  The correlations of these differentiated
signals form  new features that added to the correlation of
the original signals increase the predictive performance with
K-Nearest-Neighbor (KNN) models. The differentiated signals of a segment is a matrix
whose size is the number of channels times the product of the frequency sampling
and 599. Applying \verb@eigen@ and \verb@cor@ functions, the eigenvalues of the correlation
matrix of these differentiated signals are calculated.

With these procedures, the number of features got is the double of
the number of
channels and they are stored in a new file inside the folder
\verb@$CORG_PATH@. %$

The main flaw observed is that for human patients the differentiated signal
does not provide information due to patient data have a higher sampling frequency. We
suppose that the difference of two values in a human signal separated by a lapse
of time similar to the dog signals (1/400\,s) could improve the quality of these
features.  Nevertheless, being a minor feature, in the final track of the
competition we pay more attention to the most prominent preprocessing.

\subsection{Global statistical
  features}\label{global-statistical-features}

\section{Modelling techniques and
  training}\label{modelling-techniques-and-training}

\subsection{Cross-validation
  algorithm}\label{cross-validation-algorithm}

A cross-validation approach has been followed to compute AUC estimate using
training data. All models have been trained independently, but using the same
hyper-parameters and configurations.

The number of folds per subject is the maximum number of full
sequences\footnote{A full sequence are those where all sequence numbers are
  available, not all the available sequences are full.} in preictal data. Folds
are build in such way that all segments in the same sequence belong to
the same fold. Both, preictal and interictal data have been splitted into the
same number of folds, and following the same sequence constraint.

For KNNs, cross-validation allows to compute an estimate of the AUC, but the
final model contains all the available training data.

For Artificial Neural Networks (ANNs), one model has been trained for each
possible partition, and the test result is the mean of the output of every
model.

\subsection{Models}\label{models}

Different models have been tested in APRIl-ANN toolkit. Logistic regression as
initial baseline following a simple linear regression approach, which was not
introduced in the final system. KNNs for a more sophisticated model. In order to
exploit non-linear relations in data, dropout ANNs with different number of
layers and ReLU as neurons. And finally, an ensemble of several models has been
performed.

\subsubsection{General aspects}

Two different model specifications are possible, depending on the kind of input
features: global features model and windowed features model. The case of global
features model is the most simple, correspond to models which inputs are CORG and
COVRED features. This model receives as input all the features extracted from
one segment file, and computes how likely this file is a preictal sample. In
case of windowed features model, the model receives a file segment splitted
following a sliding window over temporal axis, and computes how likely every
window is a precital sample. Once all windows probabilities have been computed,
preictal probability of the file segment is computed as the complementary of a
geometric mean:

\begin{equation}
p(c=\text{preictal} | x) = 1 - \sqrt[n]{\prod_{t=1}^n (1 - p_t)}
\label{eq:gmean}
\end{equation}

\noindent where $x$ is a file segment, $p_t$ is the probability of window $t$
and $n$ is the number of windows. Different aggregation methods, as arithmetic
mean, maximum or harmonic mean, were tested achieving similar or worst results.

\subsubsection{K-Nearest Neighbors}\label{k-nearest-neighbors}

KNN models were chosen after convergence problems with logistic regression
models. KNNs are non-parametric and don't need to be trained, training data is
the model. The parameter number of neighbors has been set to $K=40$ after trying
different values and looking into cross-validation and public AUC scores. The
KNN hypotheses were transformed into probabilities following the implementation
given in APRIL-ANN toolkit, which is based
on~\cite{2005:nips:hinton:NCA}. Probability of preictal class is computed
following:

\begin{equation}
p(c=\text{preictal} | s) =
\displaystyle{\frac{\displaystyle{\sum_{ s^\prime \in \text{preictal}(\mathcal{K}) } exp( -||s - s^\prime||^2_2 ) }}
{\displaystyle{\sum_{s^\prime \in \mathcal{K}} exp( -||s - s^\prime||^2_2 ) }}}
\end{equation}

\noindent where $s$ is an input sample\footnote{It can be a global feature
  vector computed over the whole segment file, or a temporal window taken from
  the file.}, $\mathcal{K}$ is the set of hypoteses given by the KNN,
$\text{preictal}(\mathcal{K})$ is a subset of $\mathcal{K}$ containing only
samples belonging to preictal class. The value of $K$ and the computation of
probabilities using distances allow to reduce the impact of overfitting in the
KNN model.

\subsubsection{Artificial Neural
  Networks}\label{artificial-neural-networks}

ANN models with different hyper-parameters were tested, but in a non exhaustive
way because of the large gap between cross-validation AUC and public test
AUC. Overfitting effect was reduced by introducing a 50\%
dropout~\cite{2012:arxiv:hinton:dropout} in all hidden layers and a Gaussian
additive noise with mean $0$ and variance $0.04$ in the inputs. All proposed
ANNs have ReLU~\cite{2011:glorot:aistats} as activation functions in all hidden
layers, and logistic activation function at the output layer. Training was
performed by stochastic gradient descent with mini-batches (bunch size) of 128
samples and minimizing the cross-entropy loss function. Validation loss was also
cross-entropy but after aggregating all the probabilities computed for each
segment file following the Equation~(\ref{eq:gmean}). The input of the ANN was
extended taking into account three windows (the current, the previous one and
the following), allowing to capture temporal patterns in data. The learning rate
was set to $0.2$ with a decay parameter of $0.001$, momentum was set to $0.1$
and no other regularization term has been used. ANN weights were initialized
sampling from an uniform distribution in range $[-3,3]$.

Different hyper-parameters, including L1 and L2 regularization were tested without
good results. Again, it is important to take into account that all these
hyper-parameters were selected in a non-exhaustive way.

\subsubsection{Ensemble of models}\label{ensemble-of-models}

All the proposed models have been trained independently, computing
cross-validation probabilities for every training file, and test output
submission file.

Initially, a simple uniform linear combination of probability outputs in
submission files has been tested. In order to improve this result, a Bayesian
Model Combination (BMC) algorithm~\cite{2011:monteith:ijcnn} has been
implemented in Lua for APRIL-ANN~\cite{aprilann} toolkit. BMC algorithm uses
cross-validation output probabilities to optimize the combination weights, and
uses these weights to combine output probabilities in submission files.

\subsection{Results}\label{results}

The best submitted model is the combination of the described models
above. They achieve a \textbf{0.79335} AUC in private test.

\section{Code description}\label{code-description}

\section{Dependencies and solution recipe}\label{dependencies}

This system uses the following open source software:

\begin{itemize}
\item APRIL-ANN toolkit v0.4.0~\cite{aprilann}.
  It is a toolkit for pattern recognition with Lua and C/C++ core.
  Because this tool is very new, the installation and configuration has
  been written in the pipeline.
\item R project v3.0.2~\cite{Rproject}. For statistical
  computing, a wide spread tool in Kaggle competitions. Packages
  R.matlab, MASS, fda.usc, fastICA, stringr and plyr are necessary to
  run the system.
\item GNU BASH v4.3.11~\cite{bash} with standard command line tools.
\end{itemize}

The system is prepared to run in a Linux system with Ubuntu 14.04 LTS, but it
can be run in other Debian based distributions, but not tested.

See the README file at GitHub
repository\footnote{\url{https://github.com/ESAI-CEU-UCH/kaggle-epilepsy}} for
deeper information and the solution recipe howto,

\section{Additional comments and
  observations}\label{additional-comments-and-observations}

Among the indicated as submitted best system, different models and
features combinations have been tested. Table~\ref{tab:val} summarizes
the cross-validation AUC and public test AUC for the most important
combinations. In Table~\ref{tab:val} first column contains the model, being one
of the following:

\begin{itemize}
\item
  LR: Logistic regression.
\item
  KNN: K-Nearest-Neighbors with $K=40$.
\item ANN: Artificial Neural Networks with 50\% dropout and
  ReLU~\cite{2011:glorot:aistats} neurons, 128 units in every hidden layer, and
  a logistic activation function at the output.  ANN2 for two hidden layers,
  ANN3 for three hidden layers, and so on. ANN2p for two hidden layers with 64
  units in every layer,
\item
  UNIFORM or BMC: ensemble of the most promising systems, indicated in
  bold face. UNIFORM is a linear combination with uniformly distributed
  weights; BMC is linear combination where weights are estimated
  following BMC optimizing cross-validation likelihood.
\end{itemize}

The second column indicates which features were used as input of the
model, being one of the following list:

\begin{itemize}
\item
  FFT: the output of the proposed filter bank plus logarithm
  compression.
\item
  FFT+CORW: the previous one plus windowed eigen values of correlation
  matrix.
\item
  PCA+CORW: the PCA transformation of FFT features plus windowed eigeb
  values of correlation matrix.
\item
  ICA+CORW: idem as previos one, but using ICA instead of PCA.
\item
  CORG: correlation using 10 minutes window.
\item
  COVRED: different statistical measures over the original signal.
\item
  ENSEMBLE: output probabilities of the bold faced systems.
\end{itemize}

\begin{table}
  \centering
  \begin{tabular}{|l|l|cc|}
    \hline
    Model & Features & CV AUC & Pub. AUC\\
    \hline
    \hline
    LR & FFT & 0.9337 & 0.6784\\
    \hline
    KNN & FFT & 0.8008 & 0.6759\\
    KNN & FFT+CORW & 0.7994 & 0.7040\\
    \textbf{KNN} & \textbf{PCA+CORW} & \textbf{0.8104} & \textbf{0.7288}\\
    \textbf{KNN} & \textbf{ICA+CORW} & \textbf{0.8103} & \textbf{0.6840}\\
    \hline
    ANN2 & FFT+CORW & 0.9072 & 0.7489\\
    ANN2 & PCA+CORW & 0.9082 & 0.7815\\
    \textbf{ANN2p} & \textbf{PCA+CORW} & \textbf{0.9175} & \textbf{0.7895}\\
    \textbf{ANN2} & \textbf{ICA+CORW} & \textbf{0.9104} & \textbf{0.7772}\\
    ANN3 & PCA+CORW & 0.9188 & 0.7690\\
    ANN4 & PCA+CORW & 0.9268 & 0.7772\\
    \textbf{ANN5} & \textbf{PCA+CORW} & \textbf{0.9283} & \textbf{0.7937}\\
    ANN6 & PCA+CORW & 0.9291 & 0.7722\\
    \hline
    \textbf{KNN} & \textbf{CORG} & \textbf{0.7097} & \textbf{0.6552}\\
    \textbf{KNN} & \textbf{COVRED} & \textbf{0.6900} & \textbf{0.6901}\\
    \hline
    UNIFORM & ENSEMBLE & --- & 0.8048\\
    BMC & ENSEMBLE & 0.9271 & 0.8249\\
    \hline
  \end{tabular}
  \caption{Cross-validation and public AUC results for the most important
    systems tested during the competition.\label{tab:val}}
\end{table}            

Table~\ref{tab:val} shows that logistic regression model was the worst in
terms of generalization ability. The application of PCA allows to
improve the public AUC results by \textbf{0.025} for KNN model and
\textbf{0.033} for ANN model. ICA obtains improvements similar to PCA.
The advantage of deep ANNs (with more than two hidden layers) is not
clear, but the best public AUC was obtained by an ANN with five hidden
layers, improving by \textbf{0.004} the public AUC of the best ANN2.
Global features as CORG and COVRED show strong correlation between
cross-validation AUC and public test AUC. Finally, the use of BMC
ensemble method allow to improve the public AUC in \textbf{0.031} points
compared to the ANN5 model.

Finally, the private AUC for the two selected models is shown at
Table~\ref{tab:private}. Note that this table shows private AUC for competition
system, and private AUC for post-competition system using MKL or ATLAS
library. As it is indicated in the README at GitHub repository, the competition
system couldn't be reproduce in an exact way due to a non frozen seed number.
Now, the code has this number frozen, and its AUC is shown in the table. In
addition to this problem, our system uses Intel MKL library for the best performance
in experimentation. However, the code is configured by default to compile using
ATLAS library, which is open source and standard in Linux systems. The
post-competition private AUC for MKL and ATLAS options are also shown in the
table for comparison purposes.\footnote{Note that the system hyper-parameters
  have been optimized using MKL compilation flag, so it is expected worst
  results compiling with ATLAS library.}

\begin{table}
  \centering
  \begin{tabular}{|l|l|c||c|c|}
    \hline
          &          & Priv. AUC & \multicolumn{2}{|c|}{Post. priv. AUC}\\
    Model & FEATURES & MKL & \multicolumn{1}{|c}{MKL} & \multicolumn{1}{c|}{ATLAS} \\
    \hline
    \hline
    ANN5 & PCA+CORW & 0.7644          & 0.7644 & 0.7405\\
    BMC & ENSEMBLE & \textbf{0.7935}  & 0.7983 & 0.7910\\
    \hline
  \end{tabular}
  \caption{Private AUC for the two selected submissions. Post. priv. AUC refers
    to AUC results in private test after the competition.\label{tab:private}}
\end{table}

The private AUC of the BMC ensemble is the second best if we compare it
to all our submissions, however, the difference with the best private
AUC is not significant, the best one has a private AUC of
\textbf{0.7958}.

The experimentation has been performed in a cluster of \textbf{three}
computers with same hardware configuration:

\begin{itemize}
\item
  Dell PowerEdge 210 II server rack.
\item
  Intel Xeon E3-1220 v2 at 3.10GHz with 16GB RAM (4 cores).
\item
  2.6TB of NFS storage.
\end{itemize}

\section{Simple features and methods}\label{simple-features-and-methods}

The best single features plus model was ANN5, an artificial neural
network with 5 hidden layers using ReLUs~\cite{2011:glorot:aistats}
as activation function, with 128 neurons in every layer and logistic
activation function as output. The input features were FFT+CORW as
described above. This system achieves a \textbf{0.7644} AUC in the
private test.

\bibliography{refs}
\bibliographystyle{plain}

\end{document}
